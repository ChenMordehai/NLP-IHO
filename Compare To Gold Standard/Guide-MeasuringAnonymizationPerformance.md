# ביצועי התממה אל מול Gold Standard

[⬇️ הורדת קובץ ההפעלה (.exe)](https://drive.google.com/file/d/1lutE_qfX6sh6EvKUfrWYpI1HQfDSReAC/view?usp=drive_link)

---

## תוכן העניינים
1. [מה הכלי עושה](#מה-הכלי-עושה)
2. [איך מריצים – שלב אחרי שלב](#איך-מריצים--שלב-אחרי-שלב)
3. [משמעות התאריכים](#משמעות-התאריכים)
4. [מה כל טאב מציג](#מה-כל-טאב-מציג)
5. [מה התוצרים שנשמרים](#מה-התוצרים-שנשמרים)
6. [איך לקרוא את המדדים ומה המשמעות](#איך-לקרוא-את-המדדים-ומה-המשמעות)

---

## 1) מה הכלי עושה

הכלי משווה בין **טקסטים שתוייגו ידנית** (Gold Standard) לבין **הטקסטים לאחר התממה**, לפי מזהה רשומה משותף (_row_index_).  
לכל רשומה מחשבים אירוע(ים) של התממה ומסווגים לקטגוריות הבאות:

- **FP (False Positive) – התממת יתר** 🟥 לטיפול  
  בוצעה התממה במקום שלא נדרש.

- **TP (True Positive) – התממה מדויקת** 🟩 טוב  
  בוצעה התממה בדיוק היכן שנדרש.

- **FN (False Negative) – פספוס התממה** 🟥 לטיפול  
  מקום שנדרש לבצע בו התממה – לא בוצעה.

- **Partial TP (Partial True Positive) – התממה חלקית** 🟨 בינוני  
  בוצעה התממה על חלק מהישות/הטווח, אך לא על כולו.

לאחר הסיווג, הכלי מחשב מדדי **Precision**, **Recall**, ו-**F1** הן ברמה כללית והן **לפי תווית/תגית (Label)**, ומפיק דו"חות ותרשימים לשמירה.

---

## 2) איך מריצים – שלב אחרי שלב

1. **לוחצים** על קובץ ההרצה (`.exe`) שהורדתם.  
2. **בוחרים קבצים:**
   - **Gold Standard** – תוצר התיוג הידני, לאחר פתירת המחלוקות בין המתייגים.  
   - **Anonymization Result** – תוצאות ההתממה על אותם טקסטים (קובץ `.jsonl`).  
3. **בחירת מצב:** כולל תאריכים 🕓 או ללא תאריכים 🚫.  
4. לוחצים **Run Analysis** וממתינים לסיום.  
5. **עוברים על הטאבים** לבחינת התוצאות.  
6. **Export / שמירה:** שומרים את כל התוצרים לתיקייה ייעודית.

> 🔁 **חשוב:** מריצים _פעמיים_ – פעם **עם** תאריכים ופעם **בלי**, ושומרים כל ריצה בתיקייה נפרדת כדי שניתן יהיה להשוות ביניהן.

---

## 3) משמעות התאריכים

| כולל תאריכים | ללא תאריכים |
|---------------|--------------|
| נותן תמונה כוללת של ביצועי המודל. | מנטרל הטיית שכיחות של תאריכים. |
| לעיתים המדדים גבוהים, כי תאריכים שכיחים וקלים יחסית לזיהוי. | מודד את איכות המודל ביתר התגיות (שמות, ארגונים, מקומות, טלפונים וכו'). |

**הערה:** ההשוואה בין שתי הריצות תחשוף אם המודל נשען מדי על תגית אחת ומה מצב שאר התגיות.

---

## 4) מה כל טאב מציג

- **Summary**  
  סיכום כללי: TP / Partial / FP / FN, מדדי Precision / Recall / F1, והגדרות הריצה (כולל/ללא תאריכים).

- **Per-Label Metrics**  
  מדדים לכל תגית (Label): ספירות TP / FP / FN / Partial וצייני Precision / Recall / F1 לזיהוי תגיות חלשות.

- **Visual Analysis**  
  תרשימים המסכמים התפלגות טעויות (לדוגמה שיעור FP/FN ותגיות בעייתיות).

- **Error Analysis**  
  תובנות מילוליות: היכן מרוכזים FN / FP, דפוסים חוזרים ורעיונות לשיפור.

- **Top FN Terms**  
  מונחים/דוגמאות שהוחמצו הכי הרבה (Misses) לפי תגית – בסיס מעולה לשיפורים.

- **Top FP Terms**  
  מונחים/דוגמאות שהוסתרו שלא לצורך (Over-mask) לפי תגית – לצמצום הסתרת יתר.

- **All Differences**  
  כל האירועים עם הקשר טקסטואלי קצר (לפני/אחרי), סוג השגיאה והתגית – שימושי ל-debug נקודתי.

---

## 5) מה התוצרים שנשמרים

- `metrics.csv` – טבלת מדדים לכל תגית + סיכום כללי.  
- `differences.csv` – כל האירועים (TP / FP / FN / Partial) עם ההקשרים.  
- `summary.txt` / `errors.txt` – סיכום מילולי ותובנות לשיפור.  
- `charts.png` – תרשימי מבט-על (אם זמין).  
- `run_config.json` – פרטי ריצה (לשחזור/השוואה עתידית).

> 🔒 **רגישות מידע:** בדקו שאין בדו"חות מידע שאסור לשתף מחוץ לארגון.

---

## 6) איך לקרוא את המדדים ומה המשמעות

| מדד | הסבר | אינדיקציה לבעיה |
|------|-------|-----------------|
| **Precision** | מתוך מה **שעבר התממה** – כמה באמת נדרש לעבור התממה. | נמוך -> הרבה התממת יתר. |
| **Recall** | מתוך מה שהיה צריך **לעבור התממה** – כמה אכן עבר התממה. | נמוך -> הרבה פספוסים. |
| **F1** | הממוצע ההרמוני של Precision ו-Recall – ציון מרכזי להשוואה. | — |

---

📧 לשאלות ניתן לפנות במייל: [chenmor1@clalit.org.il](mailto:chenmor1@clalit.org.il)
